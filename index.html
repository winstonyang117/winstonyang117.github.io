<h2 style="text-align: right;"><img style="font-size: 14px; float: left;" src="https://winstonyang117.github.io/winstonyang117/winstonyang117.github.io/main/self.jpg" alt="" width="194" height="292" />Yunxiang Yang</h2>
<h2 style="text-align: right; padding-left: 30px;"><img class="alignnone  wp-image-112" src="https://winstonyang117.github.io/winstonyang117/winstonyang117.github.io/main/name.png" alt="" width="65" height="46" /></h2>
<p style="text-align: right; padding-left: 30px;">Phd Student</p>
<p style="text-align: right; padding-left: 30px;">Sensorweb Lab</p>
<p style="text-align: right; padding-left: 30px;">University of Georgia</p>
<p style="text-align: right; padding-left: 30px;">711 Boyd GSRC building</p>
<p style="text-align: right; padding-left: 30px;">200 D. W. Brooks Drive, Athens GA30602</p>
<p style="text-align: right; padding-left: 30px;">Email: yyang117@uga.edu</p>
<h3>&nbsp;</h3>
  
  
<h3>Bio</h3>
<hr />
<p>I believe each experience will build us more comprehensive. We can not connect the dots looking forward, we can only connect them looking backwards. These dots will be somehow connected in our future. Currently, I am a PhD student at the University of Georgia and advised by <a href="http://sensorweb.engr.uga.edu/index.php/song/">Dr. Wenzhan Song</a>. Prior to joining UGA, I was working as a full-time Data Scientist at UPS (Advanced Analytical Group). Besides, I obtained my M.S. and B.E. degree in Electrical Engineering from Stevens Institute of Technology (2021) and Changchun University of Science and Technology (2018), respectively. I have an interdisciplinary research background and my research interest lies broadly in vital signs monitoring and real-time estimation based on BCG & SCG signals via DNN, IoT applications, and etc. Recently, I'm working on model generalization (domain adaption) and interpretation.</p>

<h3>Publications</h3>
<hr />
<ul>
<li>Nauman Dawalatabad, <span style="text-decoration: underline;">Yuan Gong</span>, Sameer Khurana, Rhoda Au, and James Glass,&nbsp;<strong>"Detecting Dementia from Long Neuropsychological Interviews"</strong>, Proceedings of findings of the 2022 Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP 2022), Abu Dhabi, December, 2022. (to appear) </li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Jin Yu, and James Glass,&nbsp;<strong>"Vocalsound: A Dataset For Improving Human Vocal Sounds Recognition"</strong>, Proceedings of the 47th International Conference on Acoustics, Speech, & Signal Processing (ICASSP 2022), Singapore, May, 2022. &nbsp;[<a href="https://ieeexplore.ieee.org/document/9746828">Paper</a>][<a href="https://github.com/YuanGongND/vocalsound">Dataset&Code</a>][<a href="https://youtu.be/SnTwSaJ0YCo">Video</a>][<a href="https://drive.google.com/file/d/1kdaT3SZVQuDpRgOsaN8NvdqWteLe5cfl/view?usp=sharing">Slides</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Ziyi Chen, Iek-Heng Chu, Peng Chang, and James Glass,&nbsp;<strong>"Transformer-Based Multi-Aspect Multi-Granularity Non-Native English Speaker Pronunciation Assessment"</strong>, Proceedings of the 47th International Conference on Acoustics, Speech, & Signal Processing (ICASSP 2022), Singapore, May, 2022. &nbsp;[<a href="https://ieeexplore.ieee.org/document/9746743">Paper</a>][<a href="https://github.com/YuanGongND/gopt">Code</a>][<a href="https://youtu.be/vIGZWcKfdKY">Video</a>][<a href="https://drive.google.com/file/d/1XSt61-TMmMlvOBbp0ZAeRGva-gqKLquY/view?usp=sharing">Slides</a>][<a href="https://nanyang2015.github.io/blog/yu-yin/yu-yin-ping-ce/ping-fen/shen-du-xue-xi/#2022-Multi-Aspect-Multi-Granularity">Blog in Chinese</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Cheng-I Jeff Lai, Yu-An Chung, and James Glass,&nbsp;<strong>"SSAST: Self-Supervised Audio Spectrogram Transformer"</strong>, Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI 2022), Vancouver, Canada, February-March, 2022. &nbsp;[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/21315">Paper</a>][<a href="https://github.com/YuanGongND/ssast">Code</a>][<a href="https://drive.google.com/file/d/1X4d21qJUSTSBpbVjB6p3IGaDH1ulxb-U/view?usp=sharing">Slides</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Yu-An Chung, and James Glass,&nbsp;<strong>"AST: Audio Spectrogram Transformer"</strong>, Proceedings of the 22nd Conference of the International Speech Communication Association (Interspeech 2021), Brno, Czech Republic, August-September 2021.&nbsp;[<a href="https://www.isca-speech.org/archive/interspeech_2021/gong21b_interspeech.html">Paper</a>][<a href="https://github.com/YuanGongND/ast">Code</a>][<a href="https://www.youtube.com/watch?v=CSRDbqGY0Vw">Talk</a>][<a href="https://blog.csdn.net/aidanmo/article/details/122297386">Blog in Chinese</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Yu-An Chung, and James Glass,&nbsp;<strong>"PSLA: Improving Audio Tagging with Pretraining, Sampling, Labeling, and Aggregation"</strong>, IEEE Transactions on Audio, Speech and Language Processing, 2021.&nbsp;[<a href="https://ieeexplore.ieee.org/document/9576629">Paper</a>][<a href="https://github.com/YuanGongND/psla">Code</a>][<a href="https://youtu.be/DIyqRNDpSfA">Video</a>][<a href="https://drive.google.com/file/d/1_HTbloecpdQ1ZZNs-L_xuc5QDDW-TyK5/view?usp=sharing">Slides</a>][<a href="https://blog.csdn.net/rush9838465/article/details/122164791">Blog in Chinese</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Jian Yang, and Christian Poellabauer,&nbsp;<strong>"Detecting Replay Attacks Using Multi-Channel Audio: A Neural Network-Based Method"</strong>, IEEE Signal Processing Letters, 2020.&nbsp;[<a href="https://ieeexplore.ieee.org/document/9099075">Paper</a>][<a href="https://github.com/YuanGongND/multichannel-antispoof">Code</a>]</li>
<li>Bryan Xia, <span style="text-decoration: underline;">Yuan Gong</span>, Yizhe Zhang, and Christian Poellabauer,<strong> "Second-order Non-local Attention Networks for Person Re-identification"</strong>, Proceedings of the 2019 International Conference on Computer Vision (ICCV), Seoul, Korea, October-November 2019. [<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Xia_Second-Order_Non-Local_Attention_Networks_for_Person_Re-Identification_ICCV_2019_paper.pdf">Paper</a>][<a href="https://blog.csdn.net/weixin_38208912/article/details/104419781">Blog</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Jian Yang, Jacob Huber, Mitchell MacKnight, Christian Poellabauer, <strong>"ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems"</strong>, Proceedings of the 20th Conference of the International Speech Communication Association (Interspeech 2019), Graz, Austria, September 2019 (<span style="color: #ff0000;"><em>best student paper award nomination</em></span>). [<a href="https://www.isca-speech.org/archive/interspeech_2019/gong19_interspeech.html" target="_blank" rel="noopener">Paper</a>][<a href="https://github.com/YuanGongND/ReMASC" target="_blank" rel="noopener">Dataset</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Boyang Li, Christian Poellabauer, and Yiyu Shi, <strong>"Real-time Adversarial Attacks"</strong>, Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI), Macao, China, August 2019. [<a href="https://www.ijcai.org/proceedings/2019/649" target="_blank" rel="noopener">Paper</a>][<a href="https://github.com/YuanGongND/realtime-adversarial-attack">Code</a>][<a href="https://medium.com/ai%C2%B3-theory-practice-business/how-about-real-time-adversarial-attacks-6aba92d59c1e">Media</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span> and Christian Poellabauer, <strong>"</strong><strong>Deep Obfuscation: Precise Masking of Sensitive Information to Protect Against Machine Learning Adversaries (Poster)"</strong>, Proceedings of the 2018 Annual Computer Security Applications Conference Poster Session, San Juan, Puerto Rico, December 2018.</li>
<li><span style="text-decoration: underline;">Yuan Gong</span> and Christian Poellabauer, <strong>"Crafting Adversarial Examples For Speech Paralinguistics Applications"</strong>, Proceedings of the DYnamic and Novel Advances in Machine Learning and Intelligent Cyber Security (DYNAMICS) Workshop, San Juan, Puerto Rico, December 2018. [<a href="https://arxiv.org/pdf/1711.03280.pdf">Paper</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span> and Christian Poellabauer,&nbsp;<strong>"Impact of Aliasing on Deep CNN-Based End-to-End Acoustic Models"</strong>, Proceedings of the 19th Conference of the International Speech Communication Association (Interspeech 2018), Hyderabad, India, September 2018. [<a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1371.pdf">Paper</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Kevin Shin, and Christian Poellabauer,&nbsp;<strong>"Improving LIWC Using Soft Word Matching (Poster)"</strong>, Proceedings of the 9th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB), Washington, DC, August-September 2018. [<a href="https://dl.acm.org/authorize?N667629">Paper</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Hasini Yatawatte, Christian Poellabauer, Sandra Schneider, and Susan Latham,&nbsp;<strong>"Automatic Autism Spectrum Disorder Detection Using Everyday Vocalizations Captured by Smart Devices"</strong>, Proceedings of the 9th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB), Washington, DC, August-September 2018.&nbsp; </strong>[<a href="https://dl.acm.org/authorize?N667607">Paper</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span> and Christian Poellabauer,&nbsp;<strong>"Protecting Voice Controlled Systems Using Sound Source Identification Based on Acoustic Cues"</strong>, Proceedings of the 27th International Conference on Computer Communications and Networks (ICCCN), Hangzhou, China, July-August 2018.&nbsp;[<a href="https://ieeexplore.ieee.org/document/8487334/authors#authors" target="_blank" rel="noopener noreferrer">Paper</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span> and Christian Poellabauer,&nbsp;<strong>"An Overview of Vulnerabilities of Voice Controlled Systems"</strong>, Proceedings of the 1st International Workshop on Security and Privacy for the Internet-of-Things (IoTSec), Orlando, FL, April 2018.&nbsp;[<a href="https://arxiv.org/pdf/1803.09156.pdf" target="_blank" rel="noopener noreferrer">Paper</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span> and Christian Poellabauer, "<strong>Topic Modeling Based Multi-modal Depression Detection</strong>", Proceedings of the 7th Audio/Visual Emotion Challenge and Workshop (AVEC) in conjunction with ACM Multimedia (ACM-MM), Mountain View, CA, October 2017 (<span style="color: #ff0000;"><em>depression challenge winner</em></span>). [<a href="https://arxiv.org/pdf/1803.10384.pdf" target="_blank" rel="noopener noreferrer">Paper</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span> and Christian Poellabauer,&nbsp;<strong>"Continuous Assessment of Children's Emotional States using Acoustic Analysis"</strong>, Proceedings of the 5th IEEE International Conference on Healthcare Informatics (ICHI), Park City, UT, August 2017. [<a href="https://ieeexplore.ieee.org/document/8031145/" target="_blank" rel="noopener noreferrer">Paper</a>]</li>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Jin Cao, Zehui Luo, Guohui Zhou. <strong>"基于 MSP430F5529 及 CC2540 的智能型低功耗心电监测仪"</strong> (A Smart Low-Power-Consumption ECG Monitor Based on MSP430F5529 and CC2540), Chinese Journal of medical instrumentation 39.4, 2015 (<span style="color: #ff0000;"><em>project won 2014 TI national biomedical device design contest</em></span>). [<a href="http://www.cqvip.com/qk/93920x/201504/665744394.html" target="_blank" rel="noopener noreferrer">Paper</a>]&nbsp;</li>
</ul>
<h3>Preprint</h3>
<hr />
<ul>
<li><span style="text-decoration: underline;">Yuan Gong</span>, Andrew Rouditchenko, Alexander H. Liu, David Harwath, Leonid Karlinsky, Hilde Kuehne, and James Glass,&nbsp;<strong>"Contrastive Audio-Visual Masked Autoencoder"</strong>. [<a href="https://arxiv.org/abs/2210.07839">Paper</a>]
<li><span style="text-decoration: underline;">Yuan Gong</span>, Alexander H. Liu, Andrew Rouditchenko, and James Glass,&nbsp;<strong>"UAVM: A Unified Model for Audio-Visual Learning"</strong>. [<a href="https://arxiv.org/abs/2208.00061">Paper</a>]
<li><span style="text-decoration: underline;">Yuan Gong</span>, Sameer Khurana, Andrew Rouditchenko, and James Glass,&nbsp;<strong>"CMKD: CNN/Transformer-Based Cross-Model Knowledge Distillation for Audio Classification"</strong>. [<a href="https://arxiv.org/abs/2203.06760">Paper</a>]
</ul>
<h3>Awards</h3>
<hr />
<ul>
<li>INTERSPEECH 2019 Best Student Paper Award Nomination</li>
<li><a href="http://sspnet.eu/avec2017/">Depression Detection Challenge Winner</a>, the 7th ACM Multimedia Audio/Visual Emotion Challenge and Workshop (AVEC 2017)</li>
<li>IJCAI, ISCA, ICHI, NSF Travel Grant</li>
<li>Outstanding Graduate of Fudan University (2015), Fudan First Prize Scholarship (Top 3%, 2014),&nbsp;&nbsp;Outstanding Student of Dept. of Information Technology (2013),&nbsp;&nbsp;Outstanding Student of Fudan University (2012)</li>
</ul>


<h3>Contact</h3>
<hr />
<p>Please feel free to reach out (yyang117@uga.edu) if you have any questions about my work.</p>
<script type='text/javascript' id='clustrmaps' src='//clustrmaps.com/map_v2.js?d=mXzvfXKe76A1nm84mcBqfkQsNYmexfZjKeyMxBJRWlg&cl=ffffff&w=a'></script>
<p>&nbsp;</p>
